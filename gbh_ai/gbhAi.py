# python -m venv venv
# source venv/Scripts/activate
# pip install scikit-learn fastapi uvicorn

# uvicorn gbhAi:ai --host 0.0.0.0 --port 8000 --reload

import pickle
import pandas as pd
import os
import joblib

from typing import List
from pydantic import BaseModel
from fastapi import FastAPI


class TradeNamesInput(BaseModel):
    tradeNames: List[str]

class BudgetType(BaseModel):
    salary: int
    fixed_expense: float
    food_expense: float
    transportation_expense: float
    market_expense: float
    financial_expense: float
    leisure_expense: float
    coffee_expense: float
    shopping_expense: float
    emergency_expense: float



ai = FastAPI()

@ai.post("/category")
async def classify_category(data: TradeNamesInput):
    # ì €ìž¥ëœ ëª¨ë¸, ë²¡í„°í™”ê¸°, ë ˆì´ë¸” ì¸ì½”ë” ë¶ˆëŸ¬ì˜¤ê¸°
    with open('model.pkl', 'rb') as model_file:
        clf = pickle.load(model_file)

    with open('vectorizer.pkl', 'rb') as vectorizer_file:
        vectorizer = pickle.load(vectorizer_file)

    with open('label_encoder.pkl', 'rb') as le_file:
        le = pickle.load(le_file)

    # ìƒˆë¡œìš´ ìž…ë ¥ê°’
    new_names = data.tradeNames

    # ìž…ë ¥ê°’ ë²¡í„°í™”
    X_new = vectorizer.transform(new_names)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    y_pred = clf.predict(X_new)

    # ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì„ ì‹¤ì œ ì—…ì¢…ëª…ìœ¼ë¡œ ë³€í™˜
    y_pred_labels = le.inverse_transform(y_pred)

    # ê²°ê³¼ ì¶œë ¥
    result = {}
    for name, category in zip(new_names, y_pred_labels):
        result[name] = category

    return result
        
@ai.post("/type")
async def budget_type(data: BudgetType):
    # ðŸ”¹ ì €ìž¥ëœ K-Means ëª¨ë¸ & Scaler ë¶ˆëŸ¬ì˜¤ê¸°
    kmeans_loaded = joblib.load(os.path.join("kmeans_model.pkl"))
    scaler_loaded = joblib.load(os.path.join("scaler.pkl"))

    # êµ°ì§‘ -> ì‹¤ì œ ìœ í˜•
    cluster_to_type = {
        0: "ë¹„ìƒê¸ˆ",
        1: "í‰ê· ",
        2: "íŽ¸ì˜ì /ë§ˆíŠ¸",
        3: "ì»¤í”¼/ë””ì €íŠ¸",
        # 3: "êµí†µë¹„/ìžë™ì°¨",
        4: "ì‹ë¹„/ì™¸ì‹",
        # 4: "ì‹ë¹„/ì™¸ì‹",
        5: "ì‡¼í•‘",
        # 5: "ê¸ˆìœµ",
        6: "êµí†µ/ìžë™ì°¨",
        # 6: "ì‡¼í•‘",
        7: "ê¸ˆìœµ",
        # 7: "ì‡¼í•‘",
        # 7: "ì»¤í”¼/ë””ì €íŠ¸",
        8: "ì—¬ê°€ë¹„",
    }
    
    # ðŸ”¹ ìƒˆë¡œìš´ ì‚¬ìš©ìž ì†Œë¹„ íŒ¨í„´ ìž…ë ¥
    user_input = pd.DataFrame([{
        "ê³ ì •ì§€ì¶œ": data.fixed_expense,
        "ì‹ë¹„/ì™¸ì‹": data.food_expense,
        "êµí†µ/ìžë™ì°¨": data.transportation_expense,
        "íŽ¸ì˜ì /ë§ˆíŠ¸": data.market_expense,
        "ê¸ˆìœµ": data.financial_expense,
        "ì—¬ê°€ë¹„": data.leisure_expense,
        "ì»¤í”¼/ë””ì €íŠ¸": data.coffee_expense,
        "ì‡¼í•‘": data.shopping_expense,
        "ë¹„ìƒê¸ˆ": data.emergency_expense
    }])

    # ðŸ”¹ ì‚¬ìš©ìž ë°ì´í„° í‘œì¤€í™”
    user_scaled = scaler_loaded.transform(user_input)

    # ðŸ”¹ ì‚¬ìš©ìž êµ°ì§‘ ì˜ˆì¸¡
    user_cluster = kmeans_loaded.predict(user_scaled)[0]
    print(f"\nðŸ” ì‚¬ìš©ìžê°€ ì†í•œ êµ°ì§‘: {user_cluster}") # (0~8)
    print(f"âœ… ì‚¬ìš©ìž ìœ í˜•: {cluster_to_type[user_cluster]}")

    # ðŸ”¹ êµ°ì§‘í™”ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(os.path.join("êµ°ì§‘í™”ëœ_ì†Œë¹„íŒ¨í„´.csv"), encoding="cp949")

    # ðŸ”¹ ê°™ì€ êµ°ì§‘ì— ì†í•œ ë°ì´í„° ì¶”ì¶œ
    similar_cluster_data = df[df['êµ°ì§‘'] == user_cluster]
    # print("\nðŸ“Š ìœ ì‚¬í•œ êµ°ì§‘ì˜ í‰ê·  ì˜ˆì‚° ë¹„ìœ¨:")
    # print(similar_cluster_data.drop(columns=["ì›”ê¸‰", "êµ°ì§‘"]).mean().round(2))

    # í‰ê·  ê³„ì‚° í›„ ë°˜ì˜¬ë¦¼
    mean_values = similar_cluster_data.drop(columns=["ì›”ê¸‰", "êµ°ì§‘"]).mean().round(2)

    # í”„ë¡ íŠ¸ ì‚¬ìš© ì•„ëž˜ 1,2
    # ì»¬ëŸ¼ ì´ë¦„ê³¼ ê°’ì„ ì¶œë ¥
    # 1. ë‚´ ìœ í˜• ë°ì´í„° my_data
    my_data = {}
    for column, value in mean_values.items():
        my_data[column] = value
    print(f"\nðŸ“Š ìœ ì‚¬í•œ êµ°ì§‘ì˜ í‰ê·  ì˜ˆì‚° ë°ì´í„°: {my_data}")

    # 2. ë‹¤ë¥¸ ìœ í˜• ë°ì´í„° all_data
    all_data = {}
    for cluster in range(9):
        if cluster == user_cluster:
            continue
        other_cluster_data =  df[df['êµ°ì§‘'] == cluster]
        mean_values_other = other_cluster_data.drop(columns=["ì›”ê¸‰", "êµ°ì§‘"]).mean().round(2)
        # print(f"\nðŸ“Š {cluster_to_type[cluster]} í‰ê·  ì˜ˆì‚° ë°ì´í„°: {mean_values_other}")    
        data = {}
        for column, value in mean_values_other.items():
            data[column] = value
        all_data[cluster_to_type[cluster]] = data

    # print(f"\nðŸ“Š ì „ì²´ ìœ í˜• í‰ê·  ì˜ˆì‚° ë°ì´í„°: {all_data}")

    data = {
        "my_data": {cluster_to_type[user_cluster] : my_data},
        "all_data": all_data
    }

    # print(f"\nðŸ“Š ì‘ë‹µ ë°ì´í„°: {data}")
    return data


# # ì €ìž¥ëœ ëª¨ë¸, ë²¡í„°í™”ê¸°, ë ˆì´ë¸” ì¸ì½”ë” ë¶ˆëŸ¬ì˜¤ê¸°
# with open('model.pkl', 'rb') as model_file:
#     clf = pickle.load(model_file)

# with open('vectorizer.pkl', 'rb') as vectorizer_file:
#     vectorizer = pickle.load(vectorizer_file)

# with open('label_encoder.pkl', 'rb') as le_file:
#     le = pickle.load(le_file)

# # ìƒˆë¡œìš´ ìž…ë ¥ê°’
# new_names = [
#     "ì¿ íŒ¡", "ë¬´ì‹ ì‚¬",
#   "í•œì˜¥ì§‘", "ëª…ê°€ì„¤ë íƒ•",
#   "ì™•í‘¸ì°¨ì´ë‚˜", "ì°¨ì´ë‚˜íƒ€ìš´",
#   "ìœ¡í’", "í•œìš°ëª…ê°€",
#   "ì»¤í”¼í•˜ìš°ìŠ¤", "ë” ë¸Œë£¨",
#   "ìŠ¤ìœ„íŠ¸í•˜ìš°ìŠ¤", "ë² ì´ì»¤ë¦¬101",
#   "31 ì•„ì´ìŠ¤í¬ë¦¼", "ìŠ¤ë…¸ìš°ìŠ¤ìœ—",
#   "ë–¡ë§ˆì„", "í•œì˜¥ë–¡ì§‘"
# ]



# # ìž…ë ¥ê°’ ë²¡í„°í™”
# X_new = vectorizer.transform(new_names)

# # ì˜ˆì¸¡ ìˆ˜í–‰
# y_pred = clf.predict(X_new)

# # ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì„ ì‹¤ì œ ì—…ì¢…ëª…ìœ¼ë¡œ ë³€í™˜
# y_pred_labels = le.inverse_transform(y_pred)

# # ê²°ê³¼ ì¶œë ¥
# for name, category in zip(new_names, y_pred_labels):
#     # ì˜ˆì™¸ ì²˜ë¦¬ ë¶€íƒí•´ìš© ì§€ì€ì”¨
#     if name == "ì¿ íŒ¡":
#         category = "ì‡¼í•‘"
#     print(f"ìƒí˜¸ëª…: {name} -> ì˜ˆì¸¡ ì—…ì¢…: {category}")
